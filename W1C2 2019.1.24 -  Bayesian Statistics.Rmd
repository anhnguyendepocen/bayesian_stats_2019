---
title: "2019.1.24 - Class 2 Bayesian Statistics"
author: "Michael Weisner"
date: "1/24/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Probability with Discrete Variables

### Sets

+ A set is a collection of elements
+ Elements can be intervals and or isolated elements
+ One often-used set is the set of a real numbers
+ Loosely, real numbers have decimal points
+ Integers are a subset of all real numbers, $ℝ$, denoted $Z$, where the decimal places are .000...
+ Often negative numbers are excluded, eg $ℝ_+$
+ Sets can be categorical
+ In this session we are going to focus on some subset of $Z$

### Random Variables

+ A function is a rule that uniquely maps each element of an input set to some element of an output set
+ A random variable is a FUNCTION from the sample space, $\Omega$, to some subset of $ℝ$ with a probability-based rule

### Sample Space
The sample space, denoted $\Omega$, si the set of all possible outcomes of an observable random variable

LEARN GREEK ALPHABET BETTER! Look [here](https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html)

$\alpha$ and $A$ = alpha
$\beta$ and $B$ = beta
$\gamma$ and $\Gamma$ = gamma
$\delta$ and $\Delta$ = delta




Six sided dice has $\Omega$ of 1-6

Capital letters, X, indicates a random var and it's lower case indicates a realization of X.


## First Roll in Bowling

+ Each frame in bowling starts with $n = 10$ pins
+ You get 2 rolls per frame to knock down pins
+ First roll's $\Omega$ is 0-10
+ | is read as "given"

Hohn (2009) discussed distributions of the probability of knocking down $X \ge 0$ out of $n \ge X$ pins including $Pr(x | n) = F_x / (-1 + F_{x + 2})$ where $F_x$ is the xth Fibonacci number, ie $F_0 = 1$, $F_1 = 1$, and otherwise $F_x = F_{x-1} + F_{x-2}$

First 13 fibonacci numbers are 1, 1, 2, 3, 45, 8, 13, 21, 34, 55, 89, 144, and 233

## Bowling Function Example
```{r source}
# source("https://tinyurl.com/y9ubz73j")
```
```{r Bowling}
# computes the x-th Fibonacci number without recursion and with vectorization
set.seed(2019124)
F <- function(x) {
  stopifnot(is.numeric(x), all(x == as.integer(x)))
  sqrt_5 <- sqrt(5) # defined once, used twice
  golden_ratio <- (1 + sqrt_5) / 2 # appears with fibonacci sequence
  return(round(golden_ratio ^ (x + 1) / sqrt_5))
}
# probability of knocking down x out of n pins
Pr <- function(x, n = 10) return(ifelse(x > n, 0, F(x) / (-1 + F(n + 2))))

Omega <- 0:10 # 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10
round(c(Pr(Omega), total = sum(Pr(Omega))), digits = 3)

x <- sample(Omega, size = 1, prob = Pr(Omega)) # realization of random variable
```

Above shows the probability of scoring 0 - 10 on the first roll based on the fibonacci sequence

x is a sample of those distributions
```{r}
x
```

What about both rolls?

Define $X_1$ and $X_2$ to respectively be the number of pins knocked down on the first and second rolls of a frame of bowling. What function yields the probability of knocking down $x_2$ pins on your second roll?

$$
Pr(x_2 | X_1 = x_1, n = 10) = F_ ???
$$


$$PR(x_2 | X_1 = x_1, n = 10)$$ is a **CONDITIONAL** probability

Conditioning is operational...


## From Aristotelian Logic to Bivariate Probability

In R, TRUE = 1 and FALSE = 0 when doing arithmetic operations

```{r}
(TRUE & TRUE) == (TRUE * TRUE)
```

```{r}
(TRUE & FALSE) == (TRUE * FALSE)
```

Can generatlize to probabilities on the $[0,1]$ interval to compute the probability that two or more propostions are simultaneously true

$\cap$ reads as "and" **GENERAL MULTIPLICATION RULE:**
$$Pr(A \cap B) = PR(B) * Pr(A | B) = Pr(A) * Pr(B | A)$$

Loosely, A & B are independent propositions if  A being true or false tells us nothing about hte probability that B is true and vice versa...

Formally, A & B are independent if $Pr(A|B) = PR(A)$ and $Pr(B|A) = Pr(B)$. Thus, $Pr(A \cap B) = Pr(A) * Pr(B)$

**Reasonable Assumptions:**

+ Two rolls in the same frame are not independent
+ Two rolls in diff frames are independent
+ Rolls by two diff people are independent regardless of whether they are in the same frame

We ignore small things that could be dependent, like maybe a lane is warped to make people on it strike more. These sort of small factors could impact but we can't quantify it.


What are the odds of a Turkey? Three Strikes in a row...

Multiple 0.384 (the propbability of getting a strike) for each time

Aka $0.384 * 0.384 * 0.384$ or $0.384^3$


What about 9 pins on first roll and 1 pin on second? --> The General Multiplication Rule!

$Pr(9) * Pr(1)$ with the condition that 9 pins were knocked down...

$Pr(x)$

Need to fix...
```{r}
joint_Pr <- matrix(0, nrow = length(Omega), ncol = length(Omega))
rownames(joint_Pr) <- colnames(joint_Pr) <- as.character(Omega)
for (x1 in Omega) {
  Pr_x1 <- Pr(x1)
  for (x2 in 0:(10 - x1))
    joint_Pr[x1 + 1, x2 + 1] <- Pr_x1 * Pr(x2, 10 - x1)
}
sum(joint_Pr) # that sums to 1
```

```{r}
joint_Pr
```



## Composition
Stochastic Analogue to the General Multiplication Rule is composition
Randomly draw a realization of $x_1$ and use that realization of $x_1$ when randomly drawing $x_2$ from its conditional distribution

```{r}
S <- 10^6; yes <- 0
for (s in 1:S) {
  x1 <- sample(Omega, size = 1, prob = Pr(Omega))
  x2 <- sample(0:(10 - x1), size = 1, prob = Pr(0:(10 - x1), n = 10 - x1))
if (x1 == 9 & x2 == 1) yes <- yes + 1
}
c(simulated = yes / S, truth = joint_Pr["9", "1"])
```

Aristotelian Logic to Probability of Alternatives
What is the probability you fail to get a strike on this frame or the next one?
$1 - 0.384 = 0.616$ is the probability of NOT getting a strike.

**General Addition Rule**

$\cup$ is what we mean for OR:
$Pr(A \cup B) = Pr(A) + Pr(B) - Pr(A \cap B)$

Basically the probability of A + the probability of B subtracting the probability of A & B.

If $Pr(A \cup B) = 0$, then $A$ and $B$ are mutually exclusive (disjoint)


What is probability that $X_2 = 9$

Means first roll ($X_1$) must be either a 0 or 1, then $X_2$ could be 9...

so we get 0.00019 + 0.0003 + 0.118..

```{r}
round(rbind(Pr_X1 = Pr(Omega), margin1 = rowSums(joint_Pr), margin2 = colSums(joint_Pr)), 3)
```


### Marginal Distribution of Second Roll in Bowling

look at math...


## Marginal, Conditional, and Joint Probabilities

+ To compose a joint (in this case bivariate) probability, **MULTIPLY** a marginal probability by a conditional probability
+ To decompose a joint (in this case bivariate) probability, **ADD** the relevant joint probabilities to obtain a marginal probability
+ To obtain conditional probability, DIVIDE the relevant joint porbability by the relevant marginal probability since...

$$

Pr(A \cap B) = Pr(B) * Pr(A | B) = Pr(A) * Pr(B | A)

$$

$$

Pr(A | B) = (Pr(A) * \frac {Pr(B | A))} {Pr(B)} if Pr(B) > 0

$$

**This is Bayes rule!**


So, What is $Pr(X_1 = 3 | X_2 = 4, n = 10)$? Kind of a missing data problem. We know 4 were knocked down on second but didn't see how many were knocked down on first...

Prob of A (3 in first) + prob of B in the second - prob of X_2 > 4


??

Take joint probability table column of 4 and divide by 1 - sum of probability of all non 4 outcomes. That's also 1 - 1 - probability of 4.

```{r}
joint_Pr["3", "4"] / sum(joint_Pr[, "4"])
```

Basically Bayesians generalize this by taking A to be "beliefs about whatever you do not know" and B to be whatever you do know.

Frequentists accept Bayes Rule but object

## Superbowl Probability

What is the probability that the Patriots beat the Rams next Sunday?

Frequentists can't answer this question and argue it shouldn't be answered subjectively as it can only occur once...

One way to understand it from a Bayes perspective is via betting: Do you want to risk \$6 to gain \$4? If so, you believe the probability the Patriots win is greater than 0.6

$$
Odds(A) = \frac {Pr(A)} {1 - Pr(A)}
$$

Once you commit to a probability, the decision to bet is straightforward.


